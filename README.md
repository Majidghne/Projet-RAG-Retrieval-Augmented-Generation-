# Projet RAG (Retrieval-Augmented Generation) : Optimisation du Chunking

Ce dÃ©pÃ´t contient une implÃ©mentation de **Retrieval-Augmented Generation (RAG)** conÃ§ue pour dÃ©montrer l'importance cruciale de la stratÃ©gie de dÃ©coupage du texte (**chunking**) sur la qualitÃ© des rÃ©ponses d'une IA.



## ğŸ“‹ Description du Projet
L'objectif est de construire un systÃ¨me capable de rÃ©pondre Ã  des questions complexes sur un document technique (ici, un livre de thermodynamique de 39 Mo) en utilisant une base de donnÃ©es vectorielle. Le projet compare trois approches de traitement des donnÃ©es pour optimiser la pertinence sÃ©mantique.

## ğŸ› ï¸ Stack Technique
* **Base de donnÃ©es vectorielle :** ChromaDB.
* **ModÃ¨le d'Embeddings :** `all-MiniLM-L6-v2` via `sentence-transformers`.
* **LLM :** ModÃ¨les via l'API OpenRouter (ex: GPT-4o).
* **Traitement de texte :** NLTK et LangChain.

## ğŸ“‚ StratÃ©gies de Chunking ComparÃ©es

### 1. Chunking Basique (Taille fixe)
DÃ©coupage simple en blocs de 500 caractÃ¨res avec un chevauchement de 100 caractÃ¨res.
* **InconvÃ©nient :** Risque Ã©levÃ© de couper des phrases ou des idÃ©es au milieu, nuisant Ã  la cohÃ©rence sÃ©mantique.

### 2. Solution 1 : NLTK (BasÃ© sur les phrases)
Utilisation de la tokenisation par phrases pour s'assurer qu'un bloc ne s'arrÃªte jamais en plein milieu d'une idÃ©e.
* **Outil :** `sent_tokenize` de la bibliothÃ¨que NLTK.

### 3. Solution 2 : LangChain (RecursiveCharacter)
DÃ©coupage hiÃ©rarchique intelligent utilisant des sÃ©parateurs logiques (`\n\n`, `\n`, `.`, ` `).
* **Avantage :** PrÃ©serve au maximum la structure logique et sÃ©mantique du texte.



## ğŸš€ Installation et Utilisation

### PrÃ©requis
```bash
pip install chromadb openai pypdf2 python-docx sentence-transformers nltk langchain langchain-text-splitters
